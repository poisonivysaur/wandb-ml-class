{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "wandb ml-class #1",
      "provenance": [],
      "authorship_tag": "ABX9TyPDaTiItJVMMYFD5oosA/mv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/poisonivysaur/wandb-ml-class-OCR/blob/master/wandb_ml_class_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukA6VMIAwUEL",
        "colab_type": "text"
      },
      "source": [
        "# Build Your First Machine Learning Model (2019)\n",
        "\n",
        "## Optical Character Recognition from MNIST data\n",
        "\n",
        "https://www.youtube.com/watch?v=CbXj7091OWA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3sENn6SxIJl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a834b85e-2dd9-44f6-a413-d0c81e9f9da6"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWB72QI_wmVu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cc736ac3-bcbe-437e-84fd-3ea132cee4b5"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ig5JOdD_xLd0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "af49bd36-5d24-42dd-f844-dcd98c7f9f86"
      },
      "source": [
        "!git clone https://github.com/lukas/ml-class"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ml-class'...\n",
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 9021 (delta 0), reused 0 (delta 0), pack-reused 9016\u001b[K\n",
            "Receiving objects: 100% (9021/9021), 136.12 MiB | 13.16 MiB/s, done.\n",
            "Resolving deltas: 100% (2175/2175), done.\n",
            "Checking out files: 100% (5555/5555), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6gkWul4xT2G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b7220ae1-9591-40bc-d6f5-40f060a1d86e"
      },
      "source": [
        "%cd ml-class"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/ml-class\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Imz6o-nsxsyo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-8lFvFVxvVG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "846ff39d-fb39-47f5-8cb4-e0d0cf835d9e"
      },
      "source": [
        "%cd videos/intro\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/ml-class/videos/intro\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S06t8s2Xxz0T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wandb login"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99zNZRxCzAjL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "62efe8d1-a491-452c-c531-4d9cdfffc5ba"
      },
      "source": [
        "!wandb init"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mThis directory has been configured previously, should we re-configure it?\u001b[0m [y/N]: y\n",
            "What username or team should we use? [poisonivysaur]: \n",
            "Enter a name for your first project: ml-intro\n",
            "\u001b[32mThis directory is configured!  Next, track a run:\n",
            "\u001b[0m* In your training script:\n",
            "    \u001b[1mimport wandb\u001b[0m\n",
            "    \u001b[1mwandb.init(project=\"ml-intro\")\u001b[0m\n",
            "* then `\u001b[1mpython <train.py>\u001b[0m`.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXridmtezPTc",
        "colab_type": "text"
      },
      "source": [
        "How the MNIST data we're going to be working on looks like:\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/poisonivysaur/wandb-ml-class-OCR/master/mnist.png\" />"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5iteHT49BqK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "04a658c7-aec0-47c6-dfaf-5ff149d24f71"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Dropout\n",
        "from keras.utils import np_utils\n",
        "\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "\n",
        "# logging code\n",
        "run = wandb.init()\n",
        "config = run.config\n",
        "\n",
        "config.epochs = 10\n",
        "# DEBUGGING 1: train for more epochs to see if accuracy has improved etc.\n",
        "# config.epochs = 100\n",
        "\n",
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "is_five_train = y_train == 5\n",
        "is_five_test = y_test == 5\n",
        "labels = [\"Not Five\", \"Is Five\"]\n",
        "\n",
        "img_width = X_train.shape[1]\n",
        "img_height = X_train.shape[2]\n",
        "\n",
        "# create model\n",
        "model=Sequential()\n",
        "model.add(Flatten(input_shape=(img_width,img_height)))\n",
        "model.add(Dense(1, activation=\"sigmoid\"))\n",
        "model.compile(loss='mse', optimizer='adam',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X_train, is_five_train, epochs=config.epochs, validation_data=(X_test, is_five_test),\n",
        "                    callbacks=[WandbCallback(labels=labels, data_type=\"image\")])\n",
        "\n",
        "# DEBUGGING 2: will the model learn to fit in a tiny subset of data e.g. 20 \n",
        "# should be able to get a 100% accuracy just by overfitting\n",
        "# model.fit(X_train[:20, :, :], is_five_train[:20], epochs=config.epochs, validation_data=(X_test, is_five_test),\n",
        "#                     callbacks=[WandbCallback(labels=labels, data_type=\"image\")])\n",
        "\n",
        "# DEBUGGING 3: the next thing to try is to look at what the model is outputting\n",
        "# print(model.predict(X_test[:10, :, :]))\n",
        "# here we found out that outputs var between very negative numbers to numbers > 200\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/poisonivysaur/ml-intro\" target=\"_blank\">https://app.wandb.ai/poisonivysaur/ml-intro</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/poisonivysaur/ml-intro/runs/3k8nib80\" target=\"_blank\">https://app.wandb.ai/poisonivysaur/ml-intro/runs/3k8nib80</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 297.1812 - acc: 0.0466 - val_loss: 17.4970 - val_acc: 0.1025\n",
            "Epoch 2/100\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 6.2376 - acc: 0.2176 - val_loss: 1.4140 - val_acc: 0.4025\n",
            "Epoch 3/100\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 5.4392 - acc: 0.2622 - val_loss: 3.2216 - val_acc: 0.2656\n",
            "Epoch 4/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 5.7790 - acc: 0.2348 - val_loss: 16.4774 - val_acc: 0.0742\n",
            "Epoch 5/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 7.3501 - acc: 0.2097 - val_loss: 4.0649 - val_acc: 0.2457\n",
            "Epoch 6/100\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 7.2116 - acc: 0.2065 - val_loss: 6.1965 - val_acc: 0.2180\n",
            "Epoch 7/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 6.7740 - acc: 0.2517 - val_loss: 5.2059 - val_acc: 0.2271\n",
            "Epoch 8/100\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 6.4718 - acc: 0.1910 - val_loss: 3.7031 - val_acc: 0.2158\n",
            "Epoch 9/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 6.8577 - acc: 0.2024 - val_loss: 6.7275 - val_acc: 0.1368\n",
            "Epoch 10/100\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 6.4462 - acc: 0.2038 - val_loss: 14.7092 - val_acc: 0.0928\n",
            "Epoch 11/100\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 6.8675 - acc: 0.2653 - val_loss: 7.8079 - val_acc: 0.2097\n",
            "Epoch 12/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 6.5615 - acc: 0.2274 - val_loss: 2.0604 - val_acc: 0.3073\n",
            "Epoch 13/100\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 6.7427 - acc: 0.2246 - val_loss: 6.9618 - val_acc: 0.1458\n",
            "Epoch 14/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 6.7914 - acc: 0.1998 - val_loss: 10.2641 - val_acc: 0.1642\n",
            "Epoch 15/100\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 6.7707 - acc: 0.2111 - val_loss: 3.1806 - val_acc: 0.2109\n",
            "Epoch 16/100\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 6.2548 - acc: 0.2163 - val_loss: 2.1183 - val_acc: 0.1971\n",
            "Epoch 17/100\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 6.6830 - acc: 0.2024 - val_loss: 5.3783 - val_acc: 0.1883\n",
            "Epoch 18/100\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 6.7531 - acc: 0.1967 - val_loss: 7.4452 - val_acc: 0.1104\n",
            "Epoch 19/100\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 8.2346 - acc: 0.2313 - val_loss: 3.1455 - val_acc: 0.2409\n",
            "Epoch 20/100\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 5.3366 - acc: 0.2182 - val_loss: 4.8357 - val_acc: 0.1950\n",
            "Epoch 21/100\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 6.0864 - acc: 0.2149 - val_loss: 2.7289 - val_acc: 0.2448\n",
            "Epoch 22/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 7.2252 - acc: 0.2244 - val_loss: 11.5837 - val_acc: 0.1239\n",
            "Epoch 23/100\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 6.1149 - acc: 0.2101 - val_loss: 2.1862 - val_acc: 0.2936\n",
            "Epoch 24/100\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 7.4731 - acc: 0.1973 - val_loss: 8.3273 - val_acc: 0.1075\n",
            "Epoch 25/100\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 6.9501 - acc: 0.2548 - val_loss: 5.3421 - val_acc: 0.1517\n",
            "Epoch 26/100\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 6.9698 - acc: 0.1962 - val_loss: 2.6940 - val_acc: 0.2783\n",
            "Epoch 27/100\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 7.6424 - acc: 0.2030 - val_loss: 1.0926 - val_acc: 0.4472\n",
            "Epoch 28/100\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 5.5474 - acc: 0.2313 - val_loss: 11.9402 - val_acc: 0.1096\n",
            "Epoch 29/100\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 7.2552 - acc: 0.2346 - val_loss: 0.6107 - val_acc: 0.5335\n",
            "Epoch 30/100\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 6.8439 - acc: 0.2149 - val_loss: 28.9032 - val_acc: 0.0886\n",
            "Epoch 31/100\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 6.4727 - acc: 0.2007 - val_loss: 2.0736 - val_acc: 0.3100\n",
            "Epoch 32/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 5.7033 - acc: 0.2176 - val_loss: 4.5683 - val_acc: 0.1176\n",
            "Epoch 33/100\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 7.2540 - acc: 0.1802 - val_loss: 2.1130 - val_acc: 0.2865\n",
            "Epoch 34/100\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 6.5171 - acc: 0.2407 - val_loss: 1.7531 - val_acc: 0.3229\n",
            "Epoch 35/100\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 7.0068 - acc: 0.1891 - val_loss: 8.3341 - val_acc: 0.1395\n",
            "Epoch 36/100\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 5.8244 - acc: 0.2336 - val_loss: 2.3251 - val_acc: 0.2059\n",
            "Epoch 37/100\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 7.1480 - acc: 0.2129 - val_loss: 10.4091 - val_acc: 0.1556\n",
            "Epoch 38/100\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 6.4170 - acc: 0.2224 - val_loss: 13.6972 - val_acc: 0.1239\n",
            "Epoch 39/100\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 5.4953 - acc: 0.2163 - val_loss: 3.4642 - val_acc: 0.2317\n",
            "Epoch 40/100\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 8.3503 - acc: 0.2554 - val_loss: 0.9084 - val_acc: 0.4216\n",
            "Epoch 41/100\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 6.5492 - acc: 0.2277 - val_loss: 1.0000 - val_acc: 0.4238\n",
            "Epoch 42/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 7.0292 - acc: 0.2290 - val_loss: 3.1606 - val_acc: 0.1661\n",
            "Epoch 43/100\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 7.0148 - acc: 0.2006 - val_loss: 4.5691 - val_acc: 0.1808\n",
            "Epoch 44/100\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 5.4404 - acc: 0.2227 - val_loss: 7.2015 - val_acc: 0.1022\n",
            "Epoch 45/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 9.5592 - acc: 0.2554 - val_loss: 1.7273 - val_acc: 0.3379\n",
            "Epoch 46/100\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 5.6591 - acc: 0.2355 - val_loss: 4.3293 - val_acc: 0.1986\n",
            "Epoch 47/100\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 6.5771 - acc: 0.2207 - val_loss: 2.7886 - val_acc: 0.2913\n",
            "Epoch 48/100\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 7.1185 - acc: 0.2219 - val_loss: 4.6594 - val_acc: 0.2256\n",
            "Epoch 49/100\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 6.0704 - acc: 0.2216 - val_loss: 2.8434 - val_acc: 0.2672\n",
            "Epoch 50/100\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 7.4654 - acc: 0.1874 - val_loss: 2.1445 - val_acc: 0.3069\n",
            "Epoch 51/100\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 6.5862 - acc: 0.2281 - val_loss: 11.5253 - val_acc: 0.1301\n",
            "Epoch 52/100\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 7.8328 - acc: 0.2048 - val_loss: 9.2343 - val_acc: 0.1726\n",
            "Epoch 53/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 6.7071 - acc: 0.2243 - val_loss: 3.7362 - val_acc: 0.1533\n",
            "Epoch 54/100\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 5.3889 - acc: 0.2130 - val_loss: 4.0715 - val_acc: 0.2105\n",
            "Epoch 55/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 6.1627 - acc: 0.2254 - val_loss: 8.9042 - val_acc: 0.1078\n",
            "Epoch 56/100\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 7.0865 - acc: 0.2087 - val_loss: 2.4102 - val_acc: 0.3047\n",
            "Epoch 57/100\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 6.9674 - acc: 0.2337 - val_loss: 30.1361 - val_acc: 0.0837\n",
            "Epoch 58/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 6.9321 - acc: 0.2410 - val_loss: 3.1594 - val_acc: 0.2335\n",
            "Epoch 59/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 7.6448 - acc: 0.2049 - val_loss: 7.5167 - val_acc: 0.1630\n",
            "Epoch 60/100\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 5.7660 - acc: 0.2251 - val_loss: 3.8823 - val_acc: 0.2159\n",
            "Epoch 61/100\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 6.6037 - acc: 0.2113 - val_loss: 22.8909 - val_acc: 0.0533\n",
            "Epoch 62/100\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 6.5327 - acc: 0.2101 - val_loss: 1.5280 - val_acc: 0.3438\n",
            "Epoch 63/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 6.9520 - acc: 0.2185 - val_loss: 16.2509 - val_acc: 0.1496\n",
            "Epoch 64/100\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 5.9112 - acc: 0.2038 - val_loss: 1.4235 - val_acc: 0.3931\n",
            "Epoch 65/100\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 6.9546 - acc: 0.2617 - val_loss: 3.6851 - val_acc: 0.2182\n",
            "Epoch 66/100\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 7.2589 - acc: 0.2626 - val_loss: 1.5121 - val_acc: 0.3143\n",
            "Epoch 67/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 7.2440 - acc: 0.2105 - val_loss: 1.2719 - val_acc: 0.4194\n",
            "Epoch 68/100\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 6.2818 - acc: 0.2351 - val_loss: 2.5499 - val_acc: 0.2575\n",
            "Epoch 69/100\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 5.5655 - acc: 0.2107 - val_loss: 3.1069 - val_acc: 0.2035\n",
            "Epoch 70/100\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 7.9362 - acc: 0.2479 - val_loss: 0.7255 - val_acc: 0.5078\n",
            "Epoch 71/100\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 6.4990 - acc: 0.2316 - val_loss: 5.1844 - val_acc: 0.2424\n",
            "Epoch 72/100\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 8.3763 - acc: 0.1964 - val_loss: 13.0364 - val_acc: 0.1155\n",
            "Epoch 73/100\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 6.3135 - acc: 0.2666 - val_loss: 0.5718 - val_acc: 0.5460\n",
            "Epoch 74/100\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 5.4909 - acc: 0.2487 - val_loss: 1.5005 - val_acc: 0.3098\n",
            "Epoch 75/100\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 6.8760 - acc: 0.2086 - val_loss: 5.3211 - val_acc: 0.1891\n",
            "Epoch 76/100\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 7.4198 - acc: 0.1955 - val_loss: 5.5624 - val_acc: 0.1684\n",
            "Epoch 77/100\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 6.1358 - acc: 0.2181 - val_loss: 15.0511 - val_acc: 0.0797\n",
            "Epoch 78/100\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 6.4566 - acc: 0.1875 - val_loss: 5.7635 - val_acc: 0.1774\n",
            "Epoch 79/100\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 6.9075 - acc: 0.1960 - val_loss: 10.4256 - val_acc: 0.1462\n",
            "Epoch 80/100\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 7.2230 - acc: 0.2022 - val_loss: 28.4239 - val_acc: 0.0628\n",
            "Epoch 81/100\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 5.4170 - acc: 0.2393 - val_loss: 3.1787 - val_acc: 0.2559\n",
            "Epoch 82/100\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 6.4682 - acc: 0.2213 - val_loss: 0.8530 - val_acc: 0.5058\n",
            "Epoch 83/100\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 6.6724 - acc: 0.2750 - val_loss: 3.1386 - val_acc: 0.2843\n",
            "Epoch 84/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 9.7790 - acc: 0.1910 - val_loss: 1.3903 - val_acc: 0.3542\n",
            "Epoch 85/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 4.9571 - acc: 0.2684 - val_loss: 2.6362 - val_acc: 0.2606\n",
            "Epoch 86/100\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 6.6965 - acc: 0.1974 - val_loss: 5.2470 - val_acc: 0.1684\n",
            "Epoch 87/100\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 6.9426 - acc: 0.2157 - val_loss: 1.7734 - val_acc: 0.3398\n",
            "Epoch 88/100\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 6.3296 - acc: 0.2073 - val_loss: 2.5955 - val_acc: 0.2661\n",
            "Epoch 89/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 6.7436 - acc: 0.2004 - val_loss: 4.9246 - val_acc: 0.1865\n",
            "Epoch 90/100\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 5.7529 - acc: 0.2174 - val_loss: 9.8149 - val_acc: 0.1221\n",
            "Epoch 91/100\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 6.5140 - acc: 0.2487 - val_loss: 6.0961 - val_acc: 0.1800\n",
            "Epoch 92/100\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 6.2653 - acc: 0.2243 - val_loss: 1.7040 - val_acc: 0.3174\n",
            "Epoch 93/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 6.6081 - acc: 0.2083 - val_loss: 11.0244 - val_acc: 0.1225\n",
            "Epoch 94/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 7.5237 - acc: 0.1949 - val_loss: 4.7963 - val_acc: 0.2315\n",
            "Epoch 95/100\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 5.2964 - acc: 0.2663 - val_loss: 1.4092 - val_acc: 0.3460\n",
            "Epoch 96/100\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 7.0333 - acc: 0.2600 - val_loss: 3.2162 - val_acc: 0.2761\n",
            "Epoch 97/100\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 6.3959 - acc: 0.2267 - val_loss: 2.5503 - val_acc: 0.2893\n",
            "Epoch 98/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 8.9832 - acc: 0.2155 - val_loss: 5.1080 - val_acc: 0.1829\n",
            "Epoch 99/100\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 5.3002 - acc: 0.2731 - val_loss: 9.2596 - val_acc: 0.1090\n",
            "Epoch 100/100\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 7.7975 - acc: 0.1915 - val_loss: 6.8080 - val_acc: 0.1201\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdd042af240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0uWz7IHC_34",
        "colab_type": "text"
      },
      "source": [
        "### Whenever we're building machine learning models, we have 3 ways to make models better:\n",
        "\n",
        "1) improve algorithms <br>\n",
        "2) improve data prep <br>\n",
        "3) add more training data (e.g. labeling 60,000 images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GkKqVInMSFS",
        "colab_type": "text"
      },
      "source": [
        "### What we have covered in this session:\n",
        "1) Neural Network <br>\n",
        "2) Keras <br>\n",
        "3) Gradient Descent <br>\n",
        "4) Loss Functions <br>\n",
        "5) Activation Functions"
      ]
    }
  ]
}